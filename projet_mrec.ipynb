{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gk4fhSWfeTuZ"
   },
   "outputs": [],
   "source": [
    "### Verifier si flask est installé:\n",
    "#!pip show flask\n",
    "\n",
    "### installer flask si module absent:\n",
    "# !pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a-9gkeeu0OYn"
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# base_url = \"https://gutendex.com/books/?page=\"\n",
    "# library = []\n",
    "# id = 0\n",
    "\n",
    "# for i in range(1,53):\n",
    "#     response = requests.get(base_url+str(i))\n",
    "#     data = json.loads(response.text)['results']\n",
    "#     for d in data:\n",
    "#         if 'text/plain' in d['formats'] and 'image/jpeg' in d['formats']:\n",
    "#             id += 1\n",
    "#             library.append(dict(id = id, title=d['title'], image=d['formats']['image/jpeg'], content=d['formats']['text/plain']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfRSJ0oOeTuc",
    "outputId": "9589786d-9dec-4ab8-8d28-89ff3d966357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 1187 books.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "base_url = \"https://gutendex.com/books/\"\n",
    "params = {\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"page\": 1,\n",
    "}\n",
    "\n",
    "library = []\n",
    "id = 0\n",
    "\n",
    "for i in range(54):\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error occurred while retrieving data.\")\n",
    "        break\n",
    "    \n",
    "    data = response.json()['results']\n",
    "    if not data:\n",
    "        break\n",
    "    \n",
    "    for book in data:\n",
    "        if 'text/plain' in book['formats']:\n",
    "            id += 1\n",
    "            library.append({\n",
    "                \"id\": id,\n",
    "                \"title\": book['title'],\n",
    "                \"image\": book['formats']['image/jpeg'],\n",
    "                \"content\": book['formats']['text/plain']\n",
    "            })\n",
    "    params[\"page\"] += 1\n",
    "    \n",
    "print(f\"Retrieved {len(library)} books.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LppjGY7_eTue",
    "outputId": "83b797c2-c00e-460d-ecdd-418938390018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: <urlopen error [WinError 10060] Une tentative de connexion a échoué car le parti connecté n’a pas répondu convenablement au-delà d’une certaine durée ou une connexion établie a échoué car l’hôte de connexion n’a pas répondu>\n",
      "dernier de livre lu: 728\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "words_per_book = []\n",
    "book_id = 0\n",
    "\n",
    "try:\n",
    "    for book in library:\n",
    "        url = book['content']\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text = re.sub(r'[^\\w\\s]', '', response.read().decode('utf-8')).split(\"\\n\")\n",
    "\n",
    "        dictionary = defaultdict(lambda: {'name': '', 'occurrence': 0, 'book': book['id']})\n",
    "        book_id = book['id']\n",
    "        for line in text:\n",
    "            for word in line.split():\n",
    "                dictionary[word.lower()]['name'] = word.lower()\n",
    "                dictionary[word.lower()]['occurrence'] += 1\n",
    "\n",
    "        words_per_book += [\n",
    "            {'name': word['name'], 'occurrence': word['occurrence'], 'book': book['id']}\n",
    "            for word in dictionary.values()\n",
    "        ]\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "    print(\"dernier de livre lu:\",book_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8wxDp44leTug"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# save library in file (library.json) to keep it for test\n",
    "with open('library.json', 'w') as file:\n",
    "    json.dump(library, file)\n",
    "    \n",
    "# same for words_per_book\n",
    "with open('words.json', 'w') as file:\n",
    "    # write the data to the file in JSON format\n",
    "    json.dump(words_per_book, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pSWVWLeheTuh"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('library.json', 'r') as file:\n",
    "    bibliotheque = json.load(file)\n",
    "    \n",
    "with open('words.json', 'r') as file:\n",
    "    mots_livre = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8ISEp8D9eTuh"
   },
   "outputs": [],
   "source": [
    "sorted_list = sorted(mots_livre, key=lambda x: x['name'])\n",
    "\n",
    "mot = sorted_list[0]['name']\n",
    "livre = []\n",
    "index_table = {}\n",
    "\n",
    "for word in sorted_list:\n",
    "    if word['name'] != mot :\n",
    "        #  index_table.append({'token':mot,'result':livre})\n",
    "        index_table[mot] = {'token':mot,'result':livre}\n",
    "        mot = word['name']\n",
    "        livre = []\n",
    "    livre.append({'book_ref':word['book'],'occurrence':word['occurrence']})\n",
    "# index_table.append({'token':mot,'result':livre})\n",
    "index_table[mot] = {'token':mot,'result':livre}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aEpgH2BDeTuj"
   },
   "outputs": [],
   "source": [
    "### AutoCompletion\n",
    "\n",
    "def auto_completion(dict_mots, mot):\n",
    "    mots_triees = sorted(dict_mots.keys())\n",
    "    debut = 0\n",
    "    fin = len(mots_triees) - 1\n",
    "    while debut <= fin:\n",
    "        milieu = (debut + fin) // 2\n",
    "        if mots_triees[milieu].startswith(mot):\n",
    "            break\n",
    "        elif mot < mots_triees[milieu]:\n",
    "            fin = milieu - 1\n",
    "        else:\n",
    "            debut = milieu + 1\n",
    "\n",
    "    if debut > fin:\n",
    "        return []\n",
    "\n",
    "    mots_commencant = [mots_triees[milieu]]\n",
    "    i = milieu - 1\n",
    "    while i >= 0 and mots_triees[i].startswith(mot):\n",
    "        mots_commencant.insert(0, mots_triees[i])\n",
    "        i -= 1\n",
    "\n",
    "    i = milieu + 1\n",
    "    while i < len(mots_triees) and mots_triees[i].startswith(mot):\n",
    "        mots_commencant.append(mots_triees[i])\n",
    "        i += 1\n",
    "\n",
    "    return mots_commencant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tubYQ-rmeTul"
   },
   "outputs": [],
   "source": [
    "### Advanced Search Corrector\n",
    "\n",
    "def levenshtein_distance(s1, s2):\n",
    "    m, n = len(s1), len(s2)\n",
    "    if m < n:\n",
    "        return levenshtein_distance(s2, s1)\n",
    "    if n == 0:\n",
    "        return m\n",
    "    previous_row = list(range(n + 1))\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "def wagner_fischer_distance(s1, s2, max_distance):\n",
    "    m, n = len(s1), len(s2)\n",
    "    if abs(m - n) > max_distance:\n",
    "        return max_distance + 1\n",
    "    if n == 0:\n",
    "        return m\n",
    "    previous_row = list(range(n + 1))\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        min_distance = max_distance + 1\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            distance = min(insertions, deletions, substitutions)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "            current_row.append(distance)\n",
    "        if min_distance > max_distance:\n",
    "            return max_distance + 1\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "def asc(target_word,max_dist):\n",
    "    # Liste de mots avec une distance de Levenshtein de moins de 2 par rapport au mot recherché\n",
    "    results = []\n",
    "    for word in index_table:\n",
    "        distance = wagner_fischer_distance(target_word, word, max_dist)\n",
    "        if distance <= max_dist:\n",
    "            results.append(word)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UU8VPt45eTun"
   },
   "outputs": [],
   "source": [
    "# Lancement de la recherche.\n",
    "\n",
    "def find(word):\n",
    "    word = word.lower()\n",
    "    final = []\n",
    "    max_distance = 2 #distance maximale pour l'auto correcteur\n",
    "    search_result = auto_completion(index_table, word)\n",
    "    if len(search_result) == 0:\n",
    "        search_result = asc(word,max_distance)\n",
    "    for item in search_result:\n",
    "        final.append(index_table[item])\n",
    "    return final     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFUgLbT1eTun",
    "outputId": "40b43069-3503-4de8-8a9d-afdbcc4f6864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [22/Feb/2023 19:47:02] \"GET /api/v1/books/list HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2023 19:47:52] \"GET /api/v1/books/search/sarg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2023 19:48:10] \"GET /api/v1/books/search/sarg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2023 19:48:36] \"GET /api/v1/books/search/sargone HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Feb/2023 19:48:43] \"GET /api/v1/books/search/sargone HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify,make_response\n",
    "\n",
    "# Créer une instance de l'application Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "app.config['JSONIFY_PRETTYPRINT_REGULAR'] = True\n",
    "\n",
    "# Définir les routes pour l'API\n",
    "@app.route('/api/v1/books/list')\n",
    "def lists():\n",
    "    data = bibliotheque[0:book_id]\n",
    "     # Créer une réponse à partir de l'objet JSON\n",
    "    response = make_response(jsonify(data))\n",
    "\n",
    "    # Ajouter l'en-tête Content-Type à la réponse\n",
    "    response.headers['Content-Type'] = 'application/json'\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "@app.route('/api/v1/books/search/<word>')\n",
    "def search(word):\n",
    "    data = find(word)\n",
    "     # Créer une réponse à partir de l'objet JSON\n",
    "    response = make_response(jsonify(data))\n",
    "\n",
    "    # Ajouter l'en-tête Content-Type à la réponse\n",
    "    response.headers['Content-Type'] = 'application/json'\n",
    "\n",
    "    return response\n",
    "\n",
    "# Démarrer le serveur de l'application Flask\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
